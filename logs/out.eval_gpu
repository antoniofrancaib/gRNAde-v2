/home/jaf98/miniforge3/envs/rna/lib/python3.10/site-packages/Bio/Application/__init__.py:39: BiopythonDeprecationWarning: The Bio.Application modules and modules relying on it have been deprecated.

Due to the on going maintenance burden of keeping command line application
wrappers up to date, we have decided to deprecate and eventually remove these
modules.

We instead now recommend building your command line and invoking it directly
with the subprocess module.
  warnings.warn(
wandb: Currently logged in as: jaf98 (jaf98-university-of-cambridge) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: Run data is saved locally in /rds/user/jaf98/hpc-work/geometric-rna-design/wandb/wandb/run-20250216_134610-t4ofy4a2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rna_eval_v1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jaf98-university-of-cambridge/gRNAde
wandb: üöÄ View run at https://wandb.ai/jaf98-university-of-cambridge/gRNAde/runs/t4ofy4a2

CONFIG
    device: gpu
    gpu: 0
    seed: 0
    save: True
    data_path: /rds/user/jaf98/hpc-work/geometric-rna-design/data/
    radius: 4.5
    top_k: 32
    num_rbf: 32
    num_posenc: 32
    max_num_conformers: 1
    noise_scale: 0.1
    max_nodes_batch: 3000
    max_nodes_sample: 5000
    split: das
    model: ARv1
    node_in_dim: [15, 4]
    node_h_dim: [128, 16]
    edge_in_dim: [131, 3]
    edge_h_dim: [64, 4]
    num_layers: 4
    drop_rate: 0.5
    out_dim: 4
    epochs: 50
    lr: 0.0001
    label_smoothing: 0.05
    batch_size: 8
    num_workers: 8
    val_every: 5
    model_path: checkpoints/gRNAde_ARv1_1state_das.h5
    evaluate: True
    n_samples: 16
    temperature: 0.1

MODEL
    AutoregressiveMultiGNNv1(
  (W_v): Sequential(
    (0): LayerNorm(
      (scalar_norm): LayerNorm((15,), eps=1e-05, elementwise_affine=True)
    )
    (1): GVP(
      (wh): Linear(in_features=4, out_features=16, bias=False)
      (ws): Linear(in_features=31, out_features=128, bias=True)
      (wv): Linear(in_features=16, out_features=16, bias=False)
      (wsv): Linear(in_features=128, out_features=16, bias=True)
    )
  )
  (W_e): Sequential(
    (0): LayerNorm(
      (scalar_norm): LayerNorm((131,), eps=1e-05, elementwise_affine=True)
    )
    (1): GVP(
      (wh): Linear(in_features=3, out_features=4, bias=False)
      (ws): Linear(in_features=135, out_features=64, bias=True)
      (wv): Linear(in_features=4, out_features=4, bias=False)
      (wsv): Linear(in_features=64, out_features=4, bias=True)
    )
  )
  (encoder_layers): ModuleList(
    (0-3): 4 x MultiGVPConvLayer(
      (conv): MultiGVPConv()
      (norm): ModuleList(
        (0-1): 2 x LayerNorm(
          (scalar_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dropout): ModuleList(
        (0-1): 2 x Dropout(
          (sdropout): Dropout(p=0.5, inplace=False)
          (vdropout): _VDropout()
        )
      )
      (ff_func): Sequential(
        (0): GVP(
          (wh): Linear(in_features=16, out_features=32, bias=False)
          (ws): Linear(in_features=160, out_features=512, bias=True)
          (wv): Linear(in_features=32, out_features=32, bias=False)
          (wsv): Linear(in_features=512, out_features=32, bias=True)
        )
        (1): GVP(
          (wh): Linear(in_features=32, out_features=32, bias=False)
          (ws): Linear(in_features=544, out_features=128, bias=True)
          (wv): Linear(in_features=32, out_features=16, bias=False)
          (wsv): Linear(in_features=128, out_features=16, bias=True)
        )
      )
    )
  )
  (W_s): Embedding(4, 4)
  (decoder_layers): ModuleList(
    (0-3): 4 x GVPConvLayer(
      (conv): GVPConv()
      (norm): ModuleList(
        (0-1): 2 x LayerNorm(
          (scalar_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
      )
      (dropout): ModuleList(
        (0-1): 2 x Dropout(
          (sdropout): Dropout(p=0.5, inplace=False)
          (vdropout): _VDropout()
        )
      )
      (ff_func): Sequential(
        (0): GVP(
          (wh): Linear(in_features=16, out_features=32, bias=False)
          (ws): Linear(in_features=160, out_features=512, bias=True)
          (wv): Linear(in_features=32, out_features=32, bias=False)
          (wsv): Linear(in_features=512, out_features=32, bias=True)
        )
        (1): GVP(
          (wh): Linear(in_features=32, out_features=32, bias=False)
          (ws): Linear(in_features=544, out_features=128, bias=True)
          (wv): Linear(in_features=32, out_features=16, bias=False)
          (wsv): Linear(in_features=128, out_features=16, bias=True)
        )
      )
    )
  )
  (W_out): GVP(
    (wh): Linear(in_features=16, out_features=16, bias=False)
    (ws): Linear(in_features=144, out_features=4, bias=True)
  )
)
    Total parameters: 2147944

TEST DATASET
    Pre-processing 98 samples
  0%|          | 0/98 [00:00<?, ?it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 98/98 [00:00<00:00, 1102.35it/s]
    Finished: 98 pre-processed samples
Loading RibonanzaNet checkpoint: /rds/user/jaf98/hpc-work/geometric-rna-design/tools/ribonanzanet/ribonanzanet.pt
Loading RhoFold checkpoint: /rds/user/jaf98/hpc-work/geometric-rna-design/tools/rhofold/model_20221010_params.pt
  0%|          | 0/98 [00:00<?, ?it/s]  1%|          | 1/98 [00:27<44:02, 27.24s/it]  2%|‚ñè         | 2/98 [00:48<38:09, 23.85s/it]  3%|‚ñé         | 3/98 [01:09<35:49, 22.63s/it]  4%|‚ñç         | 4/98 [01:31<34:33, 22.05s/it]  5%|‚ñå         | 5/98 [01:51<33:32, 21.64s/it]  6%|‚ñå         | 6/98 [02:13<33:03, 21.56s/it]  7%|‚ñã         | 7/98 [02:34<32:21, 21.33s/it]  8%|‚ñä         | 8/98 [02:53<31:04, 20.71s/it]  9%|‚ñâ         | 9/98 [03:14<30:58, 20.89s/it] 10%|‚ñà         | 10/98 [03:36<30:57, 21.10s/it] 11%|‚ñà         | 11/98 [03:57<30:22, 20.94s/it] 12%|‚ñà‚ñè        | 12/98 [04:18<30:03, 20.97s/it] 13%|‚ñà‚ñé        | 13/98 [04:36<28:33, 20.16s/it] 14%|‚ñà‚ñç        | 14/98 [04:57<28:32, 20.38s/it] 15%|‚ñà‚ñå        | 15/98 [05:18<28:28, 20.58s/it] 16%|‚ñà‚ñã        | 16/98 [05:39<28:19, 20.72s/it] 17%|‚ñà‚ñã        | 17/98 [06:00<28:00, 20.75s/it] 18%|‚ñà‚ñä        | 18/98 [06:22<28:29, 21.36s/it] 19%|‚ñà‚ñâ        | 19/98 [06:45<28:29, 21.64s/it] 20%|‚ñà‚ñà        | 20/98 [07:07<28:25, 21.87s/it] 21%|‚ñà‚ñà‚ñè       | 21/98 [07:29<28:07, 21.92s/it] 22%|‚ñà‚ñà‚ñè       | 22/98 [07:52<28:15, 22.30s/it] 23%|‚ñà‚ñà‚ñé       | 23/98 [08:16<28:14, 22.60s/it] 24%|‚ñà‚ñà‚ñç       | 24/98 [08:38<27:39, 22.42s/it] 26%|‚ñà‚ñà‚ñå       | 25/98 [09:00<27:12, 22.37s/it] 27%|‚ñà‚ñà‚ñã       | 26/98 [09:23<26:55, 22.43s/it] 28%|‚ñà‚ñà‚ñä       | 27/98 [09:45<26:27, 22.36s/it] 29%|‚ñà‚ñà‚ñä       | 28/98 [10:07<26:06, 22.37s/it] 30%|‚ñà‚ñà‚ñâ       | 29/98 [10:30<25:46, 22.41s/it] 31%|‚ñà‚ñà‚ñà       | 30/98 [10:51<25:11, 22.23s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 31/98 [11:14<24:49, 22.23s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 32/98 [11:36<24:19, 22.11s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 33/98 [11:58<24:05, 22.24s/it] 35%|‚ñà‚ñà‚ñà‚ñç      | 34/98 [12:20<23:44, 22.26s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 35/98 [12:43<23:24, 22.29s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 36/98 [13:06<23:13, 22.47s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 37/98 [13:29<23:04, 22.69s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 38/98 [13:51<22:30, 22.51s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 39/98 [14:14<22:13, 22.60s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 40/98 [14:36<21:47, 22.54s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 41/98 [14:59<21:25, 22.55s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 42/98 [15:22<21:13, 22.74s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 43/98 [15:44<20:41, 22.57s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/98 [16:07<20:23, 22.65s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 45/98 [16:29<19:53, 22.52s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 46/98 [16:51<19:20, 22.31s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 47/98 [17:14<19:10, 22.56s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 48/98 [17:37<18:46, 22.53s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 49/98 [17:58<18:10, 22.25s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/98 [18:20<17:46, 22.23s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 51/98 [18:43<17:26, 22.26s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 52/98 [19:06<17:21, 22.64s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 53/98 [19:30<17:20, 23.13s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 54/98 [19:55<17:14, 23.52s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 55/98 [20:19<17:01, 23.76s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 56/98 [20:43<16:41, 23.83s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 57/98 [21:07<16:14, 23.77s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 58/98 [21:29<15:33, 23.34s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 59/98 [21:54<15:28, 23.82s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/98 [22:17<14:57, 23.62s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 61/98 [22:41<14:32, 23.58s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 62/98 [23:04<14:07, 23.55s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 63/98 [23:22<12:39, 21.69s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 64/98 [23:39<11:30, 20.31s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 65/98 [24:16<13:56, 25.34s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 66/98 [25:03<16:56, 31.78s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 67/98 [25:40<17:15, 33.41s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 68/98 [26:26<18:35, 37.18s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 69/98 [27:12<19:14, 39.80s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 70/98 [27:49<18:13, 39.07s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 71/98 [28:26<17:17, 38.42s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 72/98 [29:02<16:21, 37.77s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 73/98 [29:39<15:34, 37.36s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 74/98 [30:24<15:56, 39.85s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 75/98 [31:00<14:48, 38.61s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 76/98 [31:18<11:52, 32.40s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 77/98 [31:35<09:45, 27.88s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 78/98 [31:52<08:12, 24.64s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 79/98 [32:48<10:47, 34.08s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 80/98 [33:44<12:08, 40.50s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 81/98 [34:39<12:45, 45.05s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 82/98 [35:34<12:47, 47.95s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 83/98 [36:29<12:32, 50.14s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 84/98 [37:25<12:05, 51.82s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 85/98 [38:21<11:28, 52.95s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 86/98 [39:17<10:47, 53.92s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 87/98 [40:12<09:56, 54.21s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 88/98 [41:07<09:05, 54.59s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 89/98 [41:27<06:37, 44.16s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 90/98 [41:47<04:55, 36.94s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 91/98 [42:07<03:42, 31.76s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 92/98 [42:26<02:48, 28.03s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 93/98 [42:47<02:09, 25.90s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 94/98 [43:04<01:33, 23.25s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 95/98 [43:21<01:04, 21.44s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 96/98 [43:39<00:40, 20.14s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 97/98 [43:57<00:19, 19.67s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 98/98 [44:14<00:00, 18.92s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 98/98 [44:14<00:00, 27.09s/it]
BEST test recovery: 0.5278                perplexity: 1.2989                scscore: 0.6304                scscore_ribonanza: 0.2112                scscore_rmsd: 11.1728                scscore_tm: 0.2959                scscore_gdt: 0.2850                rmsd_within_thresh: 0.0421                tm_within_thresh: 0.3151                gdt_within_thresh: 0.2844
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mrna_eval_v1[0m at: [34mhttps://wandb.ai/jaf98-university-of-cambridge/gRNAde/runs/t4ofy4a2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/wandb/run-20250216_134610-t4ofy4a2/logs[0m
